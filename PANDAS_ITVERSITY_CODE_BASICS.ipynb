{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Orders.txt\")\n",
    "orders.head(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = {5:\"Jan\",\n",
    "        2:\"feb\",\n",
    "        3:\"Mar\",\n",
    "        4:\"Apr\"}\n",
    "month.keys()\n",
    "month.values()\n",
    "month[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = {5:\"Jan\",\n",
    "        2:\"feb\",\n",
    "        3:\"Mar\",\n",
    "        4:\"Apr\"}\n",
    "\n",
    "s = pd.Series(month)\n",
    "type(s)\n",
    "s\n",
    "s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,45,34,56]\n",
    "l_s = pd.Series(l)\n",
    "l_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4]\n",
    "ls = pd.Series(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_fun1(cell):\n",
    "    if(cell.upper() == 'CLOSED'):\n",
    "        return(\"Raj\")\n",
    "    else:\n",
    "        return(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema = [\"order_id\",\n",
    "                \"order_date\",\n",
    "                \"order_customer_id\",\n",
    "                \"order_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining schema\n",
    "order_items_schema = ['order_item_id',\n",
    "                     'order_item_order_id',\n",
    "                     'order_item_product_id',\n",
    "                     'order_item_quanity',\n",
    "                     'order_item_subtotal',\n",
    "                      'order_item_product_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Orders.txt\",header=None,names=orders_schema,\\\n",
    "                    converters = {\n",
    "                        'order_status':first_fun1\n",
    "                    })\n",
    "orders.head(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single condition filtering and multiple condition filterting\n",
    "orders[['order_id','order_date']]\n",
    "b = orders[orders.order_id ==3]\n",
    "a = orders[(orders.order_id == 2) & (orders.order_status =='PENDING_PAYMENT') ]\n",
    "c = orders[orders['order_id' ]== 2]\n",
    "d = orders.query('order_id ==2')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = order_items[(order_items.order_item_order_id ==2) & ((order_items.order_item_subtotal >=150) &\n",
    "                                                         (order_items.order_item_subtotal <=250)) ]\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single condition filtering and multiple condition filterting using query approach\n",
    "f = order_items.query('order_item_order_id ==2 and order_item_subtotal>=150 and order_item_subtotal<=250' )\n",
    "g = order_items.query('order_item_order_id==2 and ' +\n",
    "                     'order_item_subtotal >=150 and ' +\n",
    "                     'order_item_subtotal <=250')\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting part of string and lower functions\n",
    "orders.head(2)\n",
    "orders[orders.order_date == '2013-07-25 00:00:00.0' ]\n",
    "orders[orders.order_date.str.startswith('2013-07')]\n",
    "orders['order_status'] = orders['order_status'].str.lower()\n",
    "orders.query('order_date.str.startswith(\"2013-07-25\")',engine='python')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get no of elements and columns\n",
    "orders.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items  = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Order_items.txt\",header=None,names=order_items_schema)\n",
    "order_items.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives count of all non null values in all fields and also in specific columns\n",
    "orders.count()\n",
    "order_items.count()\n",
    "orders.count()['order_id']\n",
    "orders.count()[[('order_id'),('order_date')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives the aggegrate data of all numeric columns\n",
    "orders.describe()\n",
    "order_items.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting sum per order\n",
    "order_items[order_items.order_item_order_id==2]\n",
    "order_items[order_items.order_item_order_id ==2].order_item_subtotal.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping no.of orders per day and retriving one columns and multiple columns\n",
    "orders[orders.order_date.str.startswith(\"2013-07\")]\n",
    "orders.groupby([orders.order_date]).count()\n",
    "orders.groupby(orders.order_date)[['order_id','order_status']].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no.of orders per status\n",
    "orders.groupby(orders.order_status).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computer revenue for each order\n",
    "orders.groupby('order_id') ['order_status'].count()\n",
    "order_items.groupby('order_item_order_id')['order_item_subtotal'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computer revenue for each order another approach\n",
    "order_items.groupby('order_item_order_id')['order_item_subtotal'].\\\n",
    "agg(['sum','count','min','max','mean']).\\\n",
    "rename(columns = {\n",
    "    'count' :'Order_item_count',\n",
    "    'sum':'Order_item_sum',\n",
    "    'min':'Min_Value'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items.groupby('order_item_order_id')['order_item_subtotal'].\\\n",
    "agg(['sum','count']).\\\n",
    "rename(columns={\n",
    "    'sum':'Totoal_sum',\n",
    "    'count' : 'Totoal_count'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "order_items.rename(columns = {'order_item_order_id' : 'Order_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing back to files\n",
    "orders.to_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\tgt\\pandas_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing back to SON files and we need to use orient table option\n",
    "orders.to_json(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\tgt\\pandas_output.json\",orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting index for join\n",
    "\n",
    "orders.set_index('order_id')\n",
    "order_items.set_index('order_item_order_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining and by default it is left outer join\n",
    "orders.set_index('order_id').join\\\n",
    "(order_items.set_index('order_item_order_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.set_index('order_id').join\\\n",
    "(order_items.set_index('order_item_order_id'),how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute daly revuene per order using order date for only closed and completed orders\n",
    "orders_conisered =orders.query(\"order_status in ('complete','closed')\")\n",
    "orders_conisered.set_index('order_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders[orders.order_status.isin(['complete','closed'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = orders_conisered.set_index('order_id').join\\\n",
    "(order_items.set_index('order_item_order_id'),how ='inner').\\\n",
    "groupby('order_date')['order_item_subtotal'].agg(['sum']).\\\n",
    "rename(columns={\n",
    "    'sum':'NUEEE'\n",
    "})\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ############  CODE BASICS ####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process of cleaning messy data is called Data wrangling or Data munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\weather\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting one column and multiple colums\n",
    "df.day\n",
    "df['day']\n",
    "df[['day','event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.describe()\n",
    "df.info()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing top,bottom and middle records\n",
    "df.head()\n",
    "df.tail()\n",
    "df[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new column from exisiting column\n",
    "df['eventt'] = df['event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.temperature.max()\n",
    "df['temperature'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.temperature>32]\n",
    "df[df.temperature>32][['day','event']] \n",
    "df[df.temperature == df['temperature'].max()]\n",
    "df[df.temperature == df['temperature'].max()][['day','event']]\n",
    "df[['day','event']][df.temperature == df['temperature'].max()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seting index. We need to use inplace=True then only the set_index will be applied permanetly applied on dataframe\n",
    "df.set_index('day',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#advantage of index\n",
    "df.loc['1/2/2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting index\n",
    "df.reset_index(inplace=True)\n",
    "#df.drop(['B', 'C'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['level_0'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different ways of creating dataframe\n",
    "# dictt\n",
    "\n",
    "dictt = {\n",
    "    'day' :['1/1/2017','1/2/2017','1/3/2017'],\n",
    "    'temperature' :[32,43,56]\n",
    "}\n",
    "a = pd.DataFrame(dictt)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of tuples\n",
    "lot = [('1/1/2017',32),\n",
    "      ('1/2/2017',34)]\n",
    "b = pd.DataFrame(lot,columns=['Day','Temp'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of dictonary\n",
    "lod = [\n",
    "    {'day':'1/1/2017','Age':32},\n",
    "    {'day':'1/2/2017','Age':34}\n",
    "]\n",
    "c = pd.DataFrame(lod)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passing header\n",
    "reads = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Orders.txt\",header=None,\\\n",
    "                    names=['Order_id','Order_date','Order_Product_id','Order_status'])\n",
    "reads.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipping fist two rows and reading only rest 4 rows\n",
    "reads = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Orders.txt\",skiprows=2,nrows=4)\n",
    "reads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nulls = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Stocks\")\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing not available and n.a. with NaN in all columns\n",
    "\n",
    "nulls = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Stocks\",na_values=['not available','n.a.'])\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null values in specific columns\n",
    "nulls = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Stocks\",na_values={\n",
    "    'eps':['not available','n.a.'],\n",
    "    'people':['not available','n.a.'],\n",
    "    'revenue':['not available','n.a.',-1]\n",
    "       })\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save output into file without index\n",
    "nulls.to_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\tgt\\no_inex.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing only specific columns\n",
    "nulls.to_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\tgt\\no_index_c.csv\",index=False,columns=['eps','price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading_Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_fun(cell):\n",
    "    if(cell == 'closed'):\n",
    "        return(\"Raj\")\n",
    "    else:\n",
    "        return(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excell = pd.read_excel(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Excel_input.xlsx\",\"Excel_input\")\n",
    "excell.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling a function to apply logic on a column\n",
    "excell = pd.read_excel(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Excel_input.xlsx\",\"Excel_input\",\\\n",
    "                      converters = {\n",
    "    'order_status':first_fun\n",
    "})\n",
    "excell.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to specify the format type as .xlsx\n",
    "nulls.to_excel(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\tgt\\excel_outptu.xlsx\",sheet_name='stocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at which place we need to write in excel. Here we are skipping first row and first 2 columns\n",
    "nulls.to_excel(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\tgt\\excel_outptu.xlsx\",\\\n",
    "               sheet_name='stocks',startcol=2,startrow=1,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#effective way of writing to excels\n",
    "with pd.ExcelWriter(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\tgt\\two_sheets.xlsx\") as writer:\n",
    "                    nulls.to_excel(writer,sheet_name='stocks')\n",
    "                    reads.to_excel(writer,sheet_name='weather',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>35.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>24.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temperature  windspeed  event\n",
       "day                                      \n",
       "2017-01-01         32.0          6   Rain\n",
       "2017-01-02         35.0          7  Sunny\n",
       "2017-01-03         28.0          2    NaN\n",
       "2017-01-04         24.0          7   Snow\n",
       "2017-01-05          NaN          4   Rain\n",
       "2017-01-06         31.0          2  Sunny"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert an string into date column\n",
    "wea = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\weather\",parse_dates=['day'])\n",
    "type(wea.day[0])\n",
    "wea.set_index('day',inplace=True)\n",
    "wea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>35.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>24.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temperature  windspeed  event\n",
       "day                                      \n",
       "2017-01-01         32.0          6   Rain\n",
       "2017-01-02         35.0          7  Sunny\n",
       "2017-01-03         28.0          2      0\n",
       "2017-01-04         24.0          7   Snow\n",
       "2017-01-05          0.0          4   Rain\n",
       "2017-01-06         31.0          2  Sunny"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flling all null values with 0\n",
    "new = wea.fillna(0)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing specific columns with some values\n",
    "neww = wea.fillna({\n",
    "    'temperature':0,\n",
    "    'event':'No_event'\n",
    "})\n",
    "neww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing pervious values in the null value\n",
    "ffill = wea.fillna(method='ffill')\n",
    "ffill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing before values in the null value\n",
    "bfill = wea.fillna(method='bfill')\n",
    "bfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolate will populate mean in the places of nulls\n",
    "new_df = wea.interpolate()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it will populate nulls values with considering time. Below example does not cover the use case\n",
    "#https://www.youtube.com/watch?v=EaGbS7eWSs0&list=PLeo1K3hjS3uuASpe-1LjfG5f14Bnozjwy&index=5  (16:00)\n",
    "new_df_time = wea.interpolate(\"time\")\n",
    "new_df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will drop all the rows which as nulls\n",
    "new_drop = wea.dropna()\n",
    "new_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it will drop the columns which has all null values\n",
    "new_dropp = wea.dropna(how = \"all\") \n",
    "# It will drop the columns which has more than one null values\n",
    "#new_dropp = wea.dropna(thresh=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserting missing date. Suppose if we have date for 01 and for 4th then \n",
    "#using below statment we can populate data for 2nd & 3rd (reindex)\n",
    "dt = pd.date_range(\"2017-01-01\",\"2017-01-10\")\n",
    "idx = pd.DatetimeIndex(dt)\n",
    "df = wea.reindex(dt)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling missing data : replace function\n",
    "import numpy as np\n",
    "nedf = df.replace(np.NaN,'Rajja')\n",
    "nedf = df.replace([np.NaN,'Snow'],'Rajja')  # replacing two values with Rajja\n",
    "nedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing values at each column level with same value\n",
    "nedd = df.replace({\n",
    "    'temperature':[32,35],\n",
    "    'event':['Sunny']\n",
    "    \n",
    "},'Hero')\n",
    "nedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing values with values but in all columns\n",
    "nedd = df.replace({\n",
    "    32:35,\n",
    "    'Sunny':'Bunny'\n",
    "    \n",
    "})\n",
    "nedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expressions\n",
    "#replacing values with values but in all columns\n",
    "nedd = df.replace({\n",
    "    'event':'[A-Za-z]'\n",
    "    \n",
    "},'',regex=True)\n",
    "nedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing list of values with list of values\n",
    "dictt = pd.DataFrame({\n",
    "    'Score':['Good','Bad','Excellent','Averge','Good'],\n",
    "    'Names':['Nandu','Pandu','Laddu','Bantu','Hintu'],\n",
    "})\n",
    "dict1 = dictt.replace(\n",
    "    ['Good','Bad','Excellent','Averge'],[3,2,4,1])\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final what Is most used : Replacing multiple values in a specific columns\n",
    "\n",
    "\n",
    "dict1 = dictt.replace(\n",
    "    \n",
    "    {\n",
    "        'score':{'Good':2,'Bad':5,'Excellent':1,'Average':4}\n",
    "    }\n",
    ")\n",
    "dict1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head(3)\n",
    "g = order_items.groupby('order_item_order_id')\n",
    "for i ,ip in g:\n",
    "    print(i)\n",
    "    print(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing group by and getting all the records \n",
    "g1 = order_items.groupby('order_item_order_id')\n",
    "g1.max()\n",
    "g1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal jjoin\n",
    "orders.set_index('order_id').join\\\n",
    "(order_items.set_index('order_item_order_id'))[['order_date','order_item_product_price']].\\\n",
    "groupby('order_date')['order_item_product_price'].agg(['sum','min']).\\\n",
    "rename(columns={\n",
    "    'sum':'Total',\n",
    "    'min':'Miniumun_value'\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#union in oracle and concat in pandas\n",
    "pd.concat([orders,order_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to ignore index are else the index will be started from 1 for both the dataframes\n",
    "\n",
    "pd.concat([orders,order_items],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use keys then name will be given to the each dataframe\n",
    "al = pd.concat([orders,order_items],keys=['Orders','Order_items'])\n",
    "al.loc['Orders']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.set_index('order_id',inplace=True)\n",
    "order_items.set_index('order_item_order_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis is 0 then it will union and axis is 1 then it will join. This is not effective method\n",
    "al1 = pd.concat([orders,order_items],axis=1)\n",
    "al1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using suffixes we can suffixes the column names\n",
    "pd.merge(orders,order_item_order_id,on=\"order_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot and Pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot allows to reshape the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\weather_pivot\")\n",
    "piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv.pivot(index='date',columns='city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv.pivot(index='city',columns='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv.pivot(index='city',columns='date',values='humidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot table is used to summarize and aggregate the data inside the dataframe\n",
    "pivt = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\weather_table_pivot\")\n",
    "pivt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivt.pivot_table(index='date',columns='city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivt.pivot_table(index='city',columns='date',aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivt.pivot_table(index='date',columns='city',margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting string to date\n",
    "piv['date'] = pd.to_datetime(piv['date'])\n",
    "piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregation on monthly basis applying pivot table function\n",
    "piv.pivot_table(index=pd.Grouper(freq='M',key='date'),columns='city')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape and Melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt ---> It is used to convert row to columns\n",
    "mel = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\melt\")\n",
    "mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.melt(mel,id_vars=['day'])\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[df5['variable'] =='berlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.melt(mel,id_vars=['day'],var_name='city',value_name='Temp')\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack and UNSTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two level of column headers\n",
    "stac = pd.read_excel(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\stacks.xlsx\",header=[0,1])\n",
    "\n",
    "stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it stacked inner most level\n",
    "stac.stack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking first level\n",
    "sacked = stac.stack(level=0,dropna=True)\n",
    "sacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacked.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSSTAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two level of column headers\n",
    "cross = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\crosstab\")\n",
    "\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(cross.Nationality,cross.Handedness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(cross.Sex,cross.Handedness,margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(cross.Nationality,[cross.Sex,cross.Handedness],margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index gives percentage\n",
    "pd.crosstab(cross.Nationality,cross.Handedness,normalize = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(cross.Sex,cross.Handedness,normalize = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([cross.Sex],[cross.Handedness],values=cross.Age,aggfunc = 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date time index and resampling\n",
    "apple = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Apple\",parse_dates=['Date'],index_col='Date')\n",
    "\n",
    "#apple.index\n",
    "apple[\"2016-06\"]\n",
    "apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcutaling average of CLOSE for 2016-06\n",
    "apple[\"2016-06\"].Close.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting records for a range\n",
    "apple[\"2016-06-16\":\"2016-06-26\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting records for a range and performing aggregation\n",
    "apple[\"2016-06-16\":\"2016-06-26\"].Close.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.Close.resample('W').mean().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_r = apple.drop(['Low'],axis=1)\n",
    "#df.drop(['B', 'C'], axis=1)\n",
    "dater = apple.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining range of dates\n",
    "rng = pd.date_range(start='2016-06-16',end='2017-05-02',freq = 'B')\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting those dates as index for dater dataframes\n",
    "dater.set_index(rng,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dater.Close.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dater[\"2016-06-16\":\"2016-06-26\"].Close.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dater.asfreq('M',method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining range where we dont end date\n",
    "rng1 = pd.date_range(start='2016-06-16',periods=34,freq = 'B')\n",
    "\n",
    "rng1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adpple3 = apple.set_index(rng1,inplace=True)\n",
    "rng1 = pd.date_range(start='2016-06-16',periods=len(dater),freq = 'B')\n",
    "dater.set_index(rng1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US calendar holiday\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "usb = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "usb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rngg = pd.date_range(start='2017-07-01',end='2018-05-31',freq=usb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dater.set_index(rngg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating own birthday calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import AbstractHolidayCalendar,nearest_workday,Holiday\n",
    "class Mybirth(AbstractHolidayCalendar):\n",
    "    \"\"\"\n",
    "    US Federal Government Holiday Calendar based on rules specified by:\n",
    "    https://www.opm.gov/policy-data-oversight/\n",
    "       snow-dismissal-procedures/federal-holidays/\n",
    "    \"\"\"\n",
    "\n",
    "    rules = [\n",
    "        Holiday(\"Raj Birthday\", month=7, day=5)#, observance=nearest_workday),\n",
    "        \n",
    "    ]\n",
    "    \n",
    "myc = CustomBusinessDay(calendar=Mybirth())\n",
    "myc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2017-07-01',end='2018-05-31',freq=myc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import AbstractHolidayCalendar,nearest_workday,Holiday\n",
    "class Mybirth(AbstractHolidayCalendar):\n",
    "    \"\"\"\n",
    "    US Federal Government Holiday Calendar based on rules specified by:\n",
    "    https://www.opm.gov/policy-data-oversight/\n",
    "       snow-dismissal-procedures/federal-holidays/\n",
    "    \"\"\"\n",
    "\n",
    "    rules = [\n",
    "        Holiday(\"Raj Birthday\", month=7, day=5)#, observance=nearest_workday),\n",
    "        \n",
    "    ]\n",
    "    \n",
    "eg1 = CustomBusinessDay(weekmask='Sun Mon Tue Wed Thu',holidays=[\"2020-05-04\"])\n",
    "eg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2020-05-01',end='2020-05-31',freq=eg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to_datetime method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datee = ['2017-01-05 2:30 PM','Jan 5 2017','06/05/2017','2017.01.05','2017/01/05','20170105']\n",
    "pd.to_datetime(datee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US  dates\n",
    "pd.to_datetime('5/1/2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK dates\n",
    "pd.to_datetime('5/1/2017',dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling any date format\n",
    "pd.to_datetime('01-04$2002',format='%d-%m$%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('01-04$2002',format='%m-%d$%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignoring invald string\n",
    "datee = ['2017-01-05 2:30 PM','Jan 5 2017','06/05/2017','2017.01.05','2017/01/05','20170105','abc']\n",
    "pd.to_datetime(datee,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(datee,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling EPOCH dateformat\n",
    "t = 1591151774\n",
    "c =pd.to_datetime(t,unit='s')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.view('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'date':['2011-04-24 01:30:00.000']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['date'] - dt.datetime(1970,1,1)).dt.total_seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime(1970,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Period and Periodindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.Period('2016')\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.Period('2019-01-01',freq='M')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.Period('2010-01-25',freq='D')\n",
    "d.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pd.Period('2010-01-01',freq='W')\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Wal_period\")\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T will transpose the data\n",
    "df8.set_index('LineItem',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8['start_date'] = df8.index.map(lambda x:x.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.index = pd.PeriodIndex(df8.index,freq = 'Q-JAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 13:23:00</th>\n",
       "      <td>839383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12 03:23:00</th>\n",
       "      <td>7458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-29 04:39:23</th>\n",
       "      <td>90191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Prices\n",
       "Date_time                  \n",
       "2010-01-04 13:23:00  839383\n",
       "2010-02-12 03:23:00    7458\n",
       "2014-11-29 04:39:23   90191"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\Data_Science\\src\\Time_zones.txt\",index_col='Date_time',parse_dates=True)\n",
    "tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-01-04 13:23:00', '2010-02-12 03:23:00',\n",
       "               '2014-11-29 04:39:23'],\n",
       "              dtype='datetime64[ns]', name='Date_time', freq=None)"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-01-04 13:23:00-05:00', '2010-02-12 03:23:00-05:00',\n",
       "               '2014-11-29 04:39:23-05:00'],\n",
       "              dtype='datetime64[ns, US/Eastern]', name='Date_time', freq=None)"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz = tz.tz_localize(tz='US/Eastern')\n",
    "tz.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytz import all_timezones\n",
    "all_timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-01-04 13:23:00+01:00', '2010-02-12 03:23:00+01:00',\n",
       "               '2014-11-29 04:39:23+01:00'],\n",
       "              dtype='datetime64[ns, Europe/Berlin]', name='Date_time', freq=None)"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz1 = tz.tz_localize(tz='Europe/Berlin')\n",
    "tz1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-01-04 13:23:00+05:30', '2010-02-12 03:23:00+05:30',\n",
       "               '2014-11-29 04:39:23+05:30'],\n",
       "              dtype='datetime64[ns, Asia/Calcutta]', name='Date_time', freq=None)"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz1 = tz.tz_localize(tz='Asia/Calcutta')\n",
    "tz1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-01-04 13:23:00+05:30', '2010-02-12 03:23:00+05:30',\n",
       "               '2014-11-29 04:39:23+05:30'],\n",
       "              dtype='datetime64[ns, Asia/Calcutta]', name='Date_time', freq=None)"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz1 = tz.tz_localize(tz='Asia/Calcutta')\n",
    "tz1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "rngg = pd.date_range(start='2020-01-01',end='2020-01-30',freq='H',tz='Europe/London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-01 00:00:00+00:00', '2020-01-01 01:00:00+00:00',\n",
       "               '2020-01-01 02:00:00+00:00', '2020-01-01 03:00:00+00:00',\n",
       "               '2020-01-01 04:00:00+00:00', '2020-01-01 05:00:00+00:00',\n",
       "               '2020-01-01 06:00:00+00:00', '2020-01-01 07:00:00+00:00',\n",
       "               '2020-01-01 08:00:00+00:00', '2020-01-01 09:00:00+00:00',\n",
       "               ...\n",
       "               '2020-01-29 15:00:00+00:00', '2020-01-29 16:00:00+00:00',\n",
       "               '2020-01-29 17:00:00+00:00', '2020-01-29 18:00:00+00:00',\n",
       "               '2020-01-29 19:00:00+00:00', '2020-01-29 20:00:00+00:00',\n",
       "               '2020-01-29 21:00:00+00:00', '2020-01-29 22:00:00+00:00',\n",
       "               '2020-01-29 23:00:00+00:00', '2020-01-30 00:00:00+00:00'],\n",
       "              dtype='datetime64[ns, Europe/London]', length=697, freq='H')"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rngg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifting and Lagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 13:23:00</th>\n",
       "      <td>839383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12 03:23:00</th>\n",
       "      <td>7458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-29 04:39:23</th>\n",
       "      <td>90191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Prices\n",
       "Date_time                  \n",
       "2010-01-04 13:23:00  839383\n",
       "2010-02-12 03:23:00    7458\n",
       "2014-11-29 04:39:23   90191"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 13:23:00</th>\n",
       "      <td>7458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12 03:23:00</th>\n",
       "      <td>90191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-29 04:39:23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Prices\n",
       "Date_time                   \n",
       "2010-01-04 13:23:00   7458.0\n",
       "2010-02-12 03:23:00  90191.0\n",
       "2014-11-29 04:39:23      NaN"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 13:23:00</th>\n",
       "      <td>7458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12 03:23:00</th>\n",
       "      <td>90191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-29 04:39:23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Prices\n",
       "Date_time                   \n",
       "2010-01-04 13:23:00   7458.0\n",
       "2010-02-12 03:23:00  90191.0\n",
       "2014-11-29 04:39:23      NaN"
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "      <th>Pre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 13:23:00</th>\n",
       "      <td>839383</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12 03:23:00</th>\n",
       "      <td>7458</td>\n",
       "      <td>839383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-29 04:39:23</th>\n",
       "      <td>90191</td>\n",
       "      <td>7458.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Prices       Pre\n",
       "Date_time                            \n",
       "2010-01-04 13:23:00  839383       NaN\n",
       "2010-02-12 03:23:00    7458  839383.0\n",
       "2014-11-29 04:39:23   90191    7458.0"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz['Pre'] = tz['Prices'].shift(1)\n",
    "tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "      <th>Pre</th>\n",
       "      <th>Chnage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 13:23:00</th>\n",
       "      <td>839383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12 03:23:00</th>\n",
       "      <td>7458</td>\n",
       "      <td>839383.0</td>\n",
       "      <td>-831925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-29 04:39:23</th>\n",
       "      <td>90191</td>\n",
       "      <td>7458.0</td>\n",
       "      <td>82733.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Prices       Pre    Chnage\n",
       "Date_time                                      \n",
       "2010-01-04 13:23:00  839383       NaN       NaN\n",
       "2010-02-12 03:23:00    7458  839383.0 -831925.0\n",
       "2014-11-29 04:39:23   90191    7458.0   82733.0"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz['Chnage']  = tz['Prices'] - tz['Pre']\n",
    "tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "      <th>Pre</th>\n",
       "      <th>Chnage</th>\n",
       "      <th>five%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 13:23:00</th>\n",
       "      <td>839383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12 03:23:00</th>\n",
       "      <td>7458</td>\n",
       "      <td>839383.0</td>\n",
       "      <td>-831925.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-29 04:39:23</th>\n",
       "      <td>90191</td>\n",
       "      <td>7458.0</td>\n",
       "      <td>82733.0</td>\n",
       "      <td>-10045.481362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Prices       Pre    Chnage         five%\n",
       "Date_time                                                    \n",
       "2010-01-04 13:23:00  839383       NaN       NaN           NaN\n",
       "2010-02-12 03:23:00    7458  839383.0 -831925.0           NaN\n",
       "2014-11-29 04:39:23   90191    7458.0   82733.0 -10045.481362"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###2 day % return\n",
    "tz['five%']  = (tz['Prices'] - tz['Pre'].shift(1))*100/tz['Prices'].shift(1)\n",
    "tz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
